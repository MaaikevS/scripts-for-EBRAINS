{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating service links and linking them to file bundles\n",
    "\n",
    "With this notebook you can do the following:\n",
    "1. Query file bundles via the API\n",
    "2. Create URL instances in the KGE\n",
    "3. Create service links and link the correct file bundle to the correct URL instance\n",
    "4. Post the newly created instances to the KGE\n",
    "\n",
    "To be able to run the script, you need to the following requirements:\n",
    "- Python version >= 3.6\n",
    "- openMINDS package (can be downloaded from https://pypi.org/project/openMINDS/)\n",
    "- read and write permission to the KG via the API\n",
    "\n",
    "Information about the URL links should be stored in a .csv file with the following column names written in the correct way. **Note that more columns can be present in the csv file. They will not be used and do not affect the script.**: \n",
    "- subjectName\n",
    "- sampleName\n",
    "- fileBundle\n",
    "- URL_link\n",
    "\n",
    "The subject and sample name will be used to generate a label for the service link, which can be found under the \"view data\" tab on the dataset card. The file bundle name is used to find UUID of the file bundle in the KG so that it can be linked to the service link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "from getpass import getpass\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openMINDS\n",
    "import openMINDS.version_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "To interact with the API, you need an access token. To request a token, follow this link: https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize or copy your token from the Knowledge Graph Editor (if you have access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = getpass(prompt='Please paste your token: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract file bundle metadata from Knowledge Graph v3\n",
    "\n",
    "We are using the saved query to extract the file bundles that have already been generated in the Knowledge Graph editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"accept\": \"*/*\",\n",
    "        \"Authorization\": \"Bearer \" + token\n",
    "        }\n",
    "\n",
    "url = \"https://core.kg.ebrains.eu/v3-beta/queries/025339f7-10f0-407f-8106-bd839aab9677/instances?stage=IN_PROGRESS\"\n",
    "\n",
    "# Query results\n",
    "resp = requests.get(url, headers=headers)\n",
    "fb_info = resp.json()\n",
    "file_list = fb_info['data']\n",
    "print('\\nNumber of file bundles found: ' + str(len(file_list)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import information about service links\n",
    "\n",
    "As a next step we will import the csv file with the URLs in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the script in the same folder as the csv file or define Location of the files\n",
    "cwd = os.getcwd()\n",
    "answer = input(\"Is this where your files are stored: \" + cwd + \"? yes (y) or no (n) \" ) \n",
    "\n",
    "if answer == \"y\":\n",
    "    fpath = cwd\n",
    "elif answer == \"n\":\n",
    "    fpath = input(\"Please define you path: \")\n",
    "     \n",
    "fpath = fpath + \"\\\\\" \n",
    "os.chdir(fpath)\n",
    "\n",
    "kg_prefix = \"https://kg.ebrains.eu/api/instances/\"\n",
    "\n",
    "# Load information for the service links\n",
    "filename = input(\"What is the name of the service link file (e.g. servicelinks.csv)? \")\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instances for the URL and service links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create URL instances and service link instances\n",
    "def createInstances(df, file_list): \n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame with information to create URL and service link instances\n",
    "    file_list : List\n",
    "        List of file bundles extracted from the KGE.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas DataFrame\n",
    "        Overview of all information and newly created instances.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ask the service the service links should be opened in.\n",
    "    answer = input(\"Should the link be opened in 1) LocaliZoom or 2) Siibra-explorer: \")\n",
    "    if answer == \"1\":\n",
    "        service_atid = \"https://openminds.ebrains.eu/instances/service/LocaliZoom\"\n",
    "    elif answer == \"2\":\n",
    "        service_atid = \"https://openminds.ebrains.eu/instances/service/siibraExplorer\"\n",
    "    \n",
    "    fileBundles = df.fileBundle.unique()\n",
    "    link_dict = {}\n",
    "    url_dict = {}\n",
    "    data = pd.DataFrame([])\n",
    "    for file in file_list:\n",
    "        \n",
    "        name_file = file[\"name\"]\n",
    "            \n",
    "        # Check if file bundle exist for subject\n",
    "        if name_file in fileBundles:\n",
    "            name_sub = df.subjectName[df.index[df.fileBundle == name_file][0]]\n",
    "            tsc_name = df.sampleName[df.index[df.fileBundle == name_file][0]]\n",
    "            \n",
    "            print(\"Creating URL for subject \" + str(name_sub) + \" tissue sample collection \" + str(tsc_name) + \"\\n\")\n",
    "            \n",
    "            # initiate the collection into which you will store all metadata instances\n",
    "            mycol = helper.create_collection()\n",
    "            \n",
    "            # Create URL link \n",
    "            url_dict[name_file] = mycol.add_core_URL(URL = df.URL_link[df.index[df.fileBundle == name_file][0]])\n",
    "            \n",
    "            print(\"Creating service link for subject \" + str(name_sub) + \" file bundle \" + str(name_file) + \"\\n\")\n",
    "        \n",
    "            # Create Service link    \n",
    "            link_dict[name_file] = mycol.add_core_serviceLink(\n",
    "                dataLocation = [{\"@id\": file[\"id\"]}],\n",
    "                openDataIn = [{\"@id\": kg_prefix + url_dict[name_file].split(\"/\")[-1]}],\n",
    "                service = [{\"@id\": service_atid}]) \n",
    "            if  pd.isnull(name_sub) and pd.isnull(tsc_name):\n",
    "                label = \"tissue sample collection (subject \" + str(name_file) + \")\"\n",
    "            elif name_sub == tsc_name:\n",
    "                label = \"tissue sample collection (subject \" + str(name_sub) + \")\"\n",
    "            else:\n",
    "                label = \"tissue sample collection \" + str(tsc_name) + \" (subject \" + str(name_sub) + \")\"\n",
    "            mycol.get(link_dict[name_file]).name = label\n",
    "        \n",
    "            data = data.append(pd.DataFrame({\"subject_name\" : name_sub,\n",
    "                        \"tsc_name\" : tsc_name,\n",
    "                        \"fileBundle_name\" : name_file,  \n",
    "                        \"URL_link\" : df.URL_link[df.index[df.fileBundle == name_file][0]],\n",
    "                        \"URL_uuid\" : url_dict[name_file].split(\"/\")[-1],\n",
    "                        \"ServiceLink_uuid\" : link_dict[name_file].split(\"/\")[-1],\n",
    "                        \"ServiceLink_dataLocation_uuid\" : file[\"id\"].split(\"/\")[-1],\n",
    "                        \"ServiceLink_name\" : label,\n",
    "                        \"ServiceLink_service_atid\" : service_atid,\n",
    "                        \"DescendedFrom_name\" : file[\"descendedFrom\"][0][\"lookupLabel\"],\n",
    "                        \"DescendedFrom_atid\" : file[\"descendedFrom\"][0][\"id\"]},                \n",
    "                               index=[0]), ignore_index=True)\n",
    "        \n",
    "            mycol.save(\".\\\\\")  \n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances and save them    \n",
    "data = createInstances(df, file_list)\n",
    "data.to_csv('.\\\\serviceLinksInstances.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload instances to the Knowledge Graph editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload the instances to the KGE\n",
    "def upload(instances_fnames, token, space_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    instances_fnames : List \n",
    "        list of file paths to instances that need to be uploaded\n",
    "    token : string\n",
    "        Authorisation token to get access to the KGE\n",
    "    space_name : string\n",
    "        Space that the instances needs to be uploaded to, e.g. \"dataset\", \"common\", etc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    response : dictionary\n",
    "        For each UUID as response is stored that indications if the upload \n",
    "        was successful\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    hed = {\"accept\": \"*/*\",\n",
    "           \"Authorization\": \"Bearer \" + token,\n",
    "           \"Content-Type\": \"application/json\"\n",
    "           }\n",
    "    \n",
    "    # Prefix to upload to the right space\n",
    "    url = \"https://core.kg.ebrains.eu/v3-beta/instances/{}?space=\" + space_name\n",
    "    kg_prefix = \"https://kg.ebrains.eu/api/instances/\"\n",
    "    \n",
    "    new_instances = []\n",
    "    for fname in instances_fnames:\n",
    "        with open(fname, 'r') as f:\n",
    "            new_instances.append(json.load(f))\n",
    "        f.close()\n",
    "    \n",
    "    # Correct the capitalisation in the openMINDS package\n",
    "    for instance in new_instances:\n",
    "        atid = kg_prefix + instance[\"@id\"].split(\"/\")[-1] #only take the UUID \n",
    "        instance[\"@id\"] = atid\n",
    "        if \"openDataIn\" in instance.keys():\n",
    "            atid = kg_prefix + instance[\"openDataIn\"][0][\"@id\"].split(\"/\")[-1] #only take the UUID \n",
    "            instance[\"openDataIn\"][0][\"@id\"] = atid\n",
    "        if instance[\"@type\"].endswith(\"Servicelink\"):\n",
    "            splittype = instance[\"@type\"].split(\"/\")[:-1]\n",
    "            splittype.append(\"ServiceLink\")\n",
    "            instance[\"@type\"] = \"/\".join(splittype)\n",
    "        if instance[\"@type\"].endswith(\"Url\"):\n",
    "            splittype = instance[\"@type\"].split(\"/\")[:-1]\n",
    "            splittype.append(\"URL\")\n",
    "            instance[\"@type\"] = \"/\".join(splittype)\n",
    "    \n",
    "    # Upload to the KGE\n",
    "    print(\"\\nUploading instances now:\\n\")\n",
    "    \n",
    "    count = 0\n",
    "    response = {}    \n",
    "    for instance in new_instances:\n",
    "        count += 1\n",
    "        print(\"Posting instance \" + str(count)+\"/\"+str(len(new_instances)))\n",
    "        atid = instance[\"@id\"].split(\"/\")[-1] \n",
    "        response[atid] = requests.post(url.format(atid), json=instance, headers=hed)\n",
    "        if response[atid] == 200:\n",
    "            print(response[atid], \"OK!\" )\n",
    "        elif response[atid] == 409:\n",
    "            print(response[atid], \"Instance already exists\")\n",
    "        elif response[atid] == 401:\n",
    "            print(response[atid], \"Token not valid, authorisation not successful\")\n",
    "        else:\n",
    "            print(response[atid])\n",
    "        \n",
    "        \n",
    "    return response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload instances to the KGE\n",
    "answer = input(\"Would you like to upload the instances you created to the KGE? yes (y) or no (n) \" ) \n",
    "\n",
    "if answer == \"y\":\n",
    "    instances_fnames = glob.glob(fpath + \"*\\\\*\", recursive = True)\n",
    "\n",
    "    print(\"\\nUploading data now:\\n\")\n",
    "    \n",
    "    if token != \"\":\n",
    "        response = upload(instances_fnames, token, space_name = \"dataset\")  \n",
    "        \n",
    "elif answer == \"n\":\n",
    "    print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
